---
title: "Homework4"
author: "Zhang Zhixian-3210104129"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

We continue examining the diffusion of tetracycline among doctors in Illinois in the early 1950s, building on our work in lab 6.  You will need the data sets `ckm_nodes.csv` and `ckm_network.dat` from the labs.


1. Clean the data to eliminate doctors for whom we have no adoption-date information, as in the labs. Only use this cleaned data in the rest of the assignment.

```{r warning=FALSE}
ckm_nodes <- read.csv('D:/zhizhixian/Statistics-Computing-with-R/Data/ckm_nodes.csv')
ckm_network <- read.table('D:/zhizhixian/Statistics-Computing-with-R/Data/ckm_network.dat')
noinfor <- which(is.na(ckm_nodes$adoption_date))  # 去除NA数据
ckm_nodes <- ckm_nodes[-noinfor, ]
ckm_network <- ckm_network[-noinfor, -noinfor]
head(ckm_nodes)
```

```{r warning=FALSE}
head(ckm_network)
```

2. Create a new data frame which records, for every doctor, for every month, whether that doctor began prescribing tetracycline that month, whether they had adopted tetracycline before that month, the number of their contacts who began prescribing strictly _before_ that month, and the number of their contacts who began prescribing in that month or earlier.  Explain why the dataframe should have 6 columns, and 2125 rows.  Try not to use any loops.
```{r warning=FALSE}
ckm_nodes_new <- data.frame(doctor=row.names(ckm_nodes)) %>% slice(rep(1:n(),each=17)) %>% mutate(month=rep(1:17,length.out=n())) %>% mutate(begin = as.numeric(ckm_nodes[doctor,2]==month)) %>% mutate(adopted_before = as.numeric(ckm_nodes[doctor,2]< month))
sum1 <- function(x){
  return(sum(ckm_nodes[ckm_network[as.numeric(x[1]),]==1,2] < as.numeric(x[2])))
}
sum2 <- function(x){
  return(sum(ckm_nodes[ckm_network[as.numeric(x[1]),]==1,2] <= as.numeric(x[2])))
}
ckm_nodes_new <- ckm_nodes_new %>% mutate(contacts_adopted_before = apply(ckm_nodes_new,1,sum1))

ckm_nodes_new <- ckm_nodes_new %>% mutate(contacts_adopted_that_or_before = apply(ckm_nodes_new,1,sum2))

head(ckm_nodes_new)
```

3.  Let

$$ p_k=\rm{Pr(A\ doctor\ starts\ prescribing\ tetracycline\ this\ month \mid 
    \\
    Number\ of\ doctor’s\ contacts\ prescribing\ before\ this\ month\ = k )}$$ 
and
$$ q_k=\rm{Pr(A\ doctor\ starts\ prescribing\ tetracycline\ this\ month \mid 
    \\
    Number\ of\ doctor’s\ contacts\ prescribing\ this\ month\ = k )}$$

We suppose that $p_k$ and $q_k$ are the same for all months.

a.  Explain why there should be no more than 21 values of $k$ for which we can estimate $p_k$ and $q_k$ directly from the data.
```{r warning=FALSE}
max(apply(ckm_network,1,sum))
```
Explain:
Since the maximum of k is 20, neither $p_k$ which based on the previous month number nor $q_k$ which based on this month number nedd more than 21 values of k.


b.  Create a vector of estimated $p_k$ probabilities, using the data frame from (2). Plot the probabilities against the number of prior-adoptee contacts $k$.
```{r warning=FALSE}
total <- c()
for (k in 0:20) {
  total <- c(total,sum(na.omit(as.numeric(ckm_nodes_new[ckm_nodes_new$begin==1,]$contacts_adopted_before==k)))/sum(na.omit(as.numeric(ckm_nodes_new$contacts_adopted_before==k))))
}
# now plot it
p_k <- data.frame('pk'=total,'k'=c(0:20))
p_k %>% ggplot(aes(x=k,y=pk))+
  geom_point()+
  labs(x='Value of k',y='Probabilities pk',title='pk against the number of prior-adoptee contacts')

```

c.  Create a vector of estimated $q_k$ probabilities, using the data frame from (2). Plot the probabilities against the number of prior-or-contemporary-adoptee contacts $k$.
```{r warning=FALSE}
total <- c()
for (k in 0:20) {
  total <- c(total,sum(na.omit(as.numeric(ckm_nodes_new[ckm_nodes_new$begin==1,]$contacts_adopted_that_or_before==k)))/sum(na.omit(as.numeric(ckm_nodes_new$contacts_adopted_before==k))))
}
# now plot it
q_k <- data.frame('qk'=total,'k'=c(0:20))
q_k %>% ggplot()+
  geom_point(aes(x=k,y=qk))+
  labs(x='Value of k',y='Probabilities qk',title='qk against the number of
    prior-or-contemporary-adoptee contacts')

```

4.  Because it only conditions on information from the previous month, $p_k$ is a little easier to interpret than $q_k$. It is the probability per month that a doctor adopts tetracycline, if they have exactly $k$ contacts who had already adopted tetracycline.

a. Suppose $p_k = a + bk$. This would mean that each friend who adopts the new drug increases the probability of adoption by an equal amount. Estimate this model by least squares, using the values you constructed in (3b). Report the parameter estimates.
```{r warning=FALSE}
fit_pk1 <- lm(pk~k,data=p_k)
summary(fit_pk1)
```

b.  Suppose $p_k = e^{a+bk}/(1 + e^{a+bk})$. Explain, in words, what this model would imply about the impact of adding one more adoptee friend on a given doctor's probability of adoption. (You can suppose that $b > 0$, if that makes it easier.) Estimate the model by least squares, using the values you constructed in (3b).
```{r warning=FALSE}
fit_pk2 <- nls(pk~exp(a+b*k)/(1+exp(a+b*k)),data=p_k,start=list(a=1,b=0.5))
summary(fit_pk2)
```
    
c.  Plot the values from (3b) along with the estimated curves from (4a) and (4b). (You should have one plot, with $k$ on the horizontal axis, and probabilities on the vertical axis .) Which model do you prefer, and why?
```{r warning=FALSE}
y1 <- predict(fit_pk1,data.frame(k=c(0:20)))
y2 <- predict(fit_pk2,data.frame(k=c(0:20)))
p_k <- p_k %>% mutate(linear=y1) %>% mutate(nonlinear=y2)
ggplot(data = p_k)+
  geom_point(aes(x=k,y=pk))+
  geom_line(aes(x=k,y=linear),col='red')+
  geom_smooth(aes(x=k,y=nonlinear),col='blue')+
  labs(title='pks and estimated curves',
       x='value of k',
       y='possibilities pk')
```
Obviously the second one, that is, the logistic one is better.
    
    
_For quibblers, pedants, and idle hands itching for work to do_: The $p_k$ values from problem 3 aren't all equally precise, because they come from different numbers of observations.  Also, if each doctor with $k$ adoptee contacts is independently deciding whether or not to adopt with probability $p_k$, then the variance in the number of adoptees will depend on $p_k$.  Say that the actual proportion who decide to adopt is $\hat{p}_k$.  A little probability (exercise!) shows that in this situation, $\mathbb{E}[\hat{p}_k] = p_k$, but that $\mathrm{Var}[\hat{p}_k] = p_k(1-p_k)/n_k$, where $n_k$ is the number of doctors in that situation.  (We estimate probabilities more precisely when they're really extreme [close to 0 or 1], and/or we have lots of observations.)  We can estimate that variance as $\hat{V}_k = \hat{p}_k(1-\hat{p}_k)/n_k$.  Find the $\hat{V}_k$, and then re-do the estimation in (4a) and (4b) where the squared error for $p_k$ is divided by $\hat{V}_k$.  How much do the parameter estimates change?  How much do the plotted curves in (4c) change?

Probability exercise:
Assume there are $n_k$ observations $x_1,x_2,...,x_{nk}$. And $x_i=1$ if the doctor adopts in month $k$, while $x_i=0$ on the other side. The distribution is binomial, that is $P(x_i=1)=p_k$ and $P(x_i=0)=1-p_k$, so $\mathbb{E}(x_i) = p_k$ and $\mathrm{Var}(x_i) = p_k(1-p_k)/n_k$. Thus $\mathbb{E}[\hat{p}_k] = p_k$ and $\mathrm{Var}[\hat{p}_k] = p_k(1-p_k)/n_k$

```{r warning=FALSE}
p.vec <- vector(mode = "numeric",length = 21)
k.vec <- p.vec

for(k in 0:20){
  idx <- na.omit(ckm_nodes_new$contacts_adopted_before == k)
  k.vec[k+1] <- sum(idx)
  if(k.vec[k+1] == 0){
    p.vec[k+1] <- NA
    next
  }
  ckm_nodes_new_k <- ckm_nodes_new[idx,]
  p1 <- sum(ckm_nodes_new_k$begin == 1)
  p.vec[k+1] <- p1/k.vec[k+1]
}

p.vec2 <- vector(mode = "numeric",length = 21)
k.vec2 <- p.vec2
for(k in 0:20){
  idx <- na.omit((ckm_nodes_new$contacts_adopted_that_or_before - ckm_nodes_new$contacts_adopted_that_or_before) == k)
  k.vec2[k+1] <- sum(idx)
  if(k.vec2[k+1] == 0){
    p.vec2[k+1] <- NA
    next
  }
  ckm_nodes_new_k <- ckm_nodes_new[idx,]
  p1 <- sum(ckm_nodes_new_k$prescribe_that_month == 1)
  p.vec2[k+1] <- p1/k.vec2[k+1]
}

```

```{r warning=FALSE}
idx <- !(is.na(p.vec) | p.vec == 0)
wt <- p.vec*(1-p.vec)/k.vec
m1 <- lm(pk ~ k, data = p_k[idx,], weight = 1/wt[idx])
m2 <- nls(pk ~ exp(a+b*k)/(1+exp(a+b*k)),data = p_k[idx,], start = list(a = 0, b = -0.2), weight = 1/wt[idx])

```

The change of parameters:

```{r warning=FALSE}
w1 = predict(m1, newdata=data.frame(k=c(0:20)))
w2 = predict(m2, newdata=data.frame(k=c(0:20)))

df.w <- data.frame(k = 0:20, p = p.vec)
df.w <- mutate(df.w, linear = w1, logistic = w2)
dft <- df.w %>% gather(model, res, -k) %>% na.omit()
dft %>% ggplot() + 
  geom_point(aes(x = k, y = res, color = model), size = 3) +
  geom_line(aes(x = k, y = res, color = model), size = 1) +
  labs(y = "Probability",title = "Prediction of linear and logistic models with weight")
```

Both curves are more fitting when $k$ is small. The reason can be that smaller samples cause larger estimated variances, which reduce the weight of there points, and there are more observations when $k$ is small, which adds to the weight.







